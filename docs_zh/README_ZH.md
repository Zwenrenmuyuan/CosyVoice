[![SVG Banners](https://svg-banners.vercel.app/api?type=origin&text1=CosyVoiceğŸ¤ &text2=æ–‡æœ¬è½¬è¯­éŸ³%20ğŸ’–%20å¤§è¯­è¨€æ¨¡å‹&width=800&height=210)](https://github.com/Akshay090/svg-banners)

## ğŸ‘‰ğŸ» CosyVoice ğŸ‘ˆğŸ»
**CosyVoice 2.0**: [æ¼”ç¤º](https://funaudiollm.github.io/cosyvoice2/); [è®ºæ–‡](https://arxiv.org/abs/2412.10117); [Modelscope](https://www.modelscope.cn/studios/iic/CosyVoice2-0.5B); [HuggingFace](https://huggingface.co/spaces/FunAudioLLM/CosyVoice2-0.5B)

**CosyVoice 1.0**: [æ¼”ç¤º](https://fun-audio-llm.github.io); [è®ºæ–‡](https://funaudiollm.github.io/pdf/CosyVoice_v1.pdf); [Modelscope](https://www.modelscope.cn/studios/iic/CosyVoice-300M)

## äº®ç‚¹ğŸ”¥

**CosyVoice 2.0** å·²ç»å‘å¸ƒï¼ä¸1.0ç‰ˆæœ¬ç›¸æ¯”ï¼Œæ–°ç‰ˆæœ¬æä¾›äº†æ›´å‡†ç¡®ã€æ›´ç¨³å®šã€æ›´å¿«é€Ÿã€æ›´ä¼˜è´¨çš„è¯­éŸ³ç”Ÿæˆèƒ½åŠ›ã€‚

### å¤šè¯­è¨€æ”¯æŒ
- **æ”¯æŒè¯­è¨€**ï¼šä¸­æ–‡ã€è‹±è¯­ã€æ—¥è¯­ã€éŸ©è¯­ã€ä¸­å›½æ–¹è¨€ï¼ˆç²¤è¯­ã€å››å·è¯ã€ä¸Šæµ·è¯ã€å¤©æ´¥è¯ã€æ­¦æ±‰è¯ç­‰ï¼‰
- **è·¨è¯­è¨€ä¸æ··åˆè¯­è¨€**ï¼šæ”¯æŒè·¨è¯­è¨€å’Œä»£ç åˆ‡æ¢åœºæ™¯çš„é›¶æ ·æœ¬å£°éŸ³å…‹éš†ã€‚

### è¶…ä½å»¶è¿Ÿ
- **åŒå‘æµå¼æ”¯æŒ**ï¼šCosyVoice 2.0 æ•´åˆäº†ç¦»çº¿å’Œæµå¼å»ºæ¨¡æŠ€æœ¯ã€‚
- **å¿«é€Ÿé¦–åŒ…åˆæˆ**ï¼šå®ç°ä½è‡³150æ¯«ç§’çš„å»¶è¿Ÿï¼ŒåŒæ—¶ä¿æŒé«˜è´¨é‡éŸ³é¢‘è¾“å‡ºã€‚

### é«˜ç²¾åº¦
- **æ”¹è¿›å‘éŸ³**ï¼šä¸CosyVoice 1.0ç›¸æ¯”ï¼Œå‘éŸ³é”™è¯¯å‡å°‘30%åˆ°50%ã€‚
- **åŸºå‡†æµ‹è¯•æˆå°±**ï¼šåœ¨Seed-TTSè¯„ä¼°é›†çš„å›°éš¾æµ‹è¯•é›†ä¸Šè¾¾åˆ°æœ€ä½å­—ç¬¦é”™è¯¯ç‡ã€‚

### å¼ºç¨³å®šæ€§
- **éŸ³è‰²ä¸€è‡´æ€§**ï¼šç¡®ä¿é›¶æ ·æœ¬å’Œè·¨è¯­è¨€è¯­éŸ³åˆæˆçš„å¯é å£°éŸ³ä¸€è‡´æ€§ã€‚
- **è·¨è¯­è¨€åˆæˆ**ï¼šä¸1.0ç‰ˆæœ¬ç›¸æ¯”æœ‰æ˜¾è‘—æ”¹è¿›ã€‚

### è‡ªç„¶ä½“éªŒ
- **å¢å¼ºéŸµå¾‹å’ŒéŸ³è´¨**ï¼šæ”¹è¿›åˆæˆéŸ³é¢‘çš„å¯¹é½ï¼Œå°†MOSè¯„ä¼°åˆ†æ•°ä»5.4æå‡åˆ°5.53ã€‚
- **æƒ…æ„Ÿå’Œæ–¹è¨€çµæ´»æ€§**ï¼šç°åœ¨æ”¯æŒæ›´ç»†ç²’åº¦çš„æƒ…æ„Ÿæ§åˆ¶å’Œå£éŸ³è°ƒæ•´ã€‚

## å‘å±•è·¯çº¿å›¾

- [x] 2025/05
    - [x] æ·»åŠ cosyvoice 2.0 vllmæ”¯æŒ

- [x] 2024/12
    - [x] å‘å¸ƒ25hz cosyvoice 2.0

- [x] 2024/09
    - [x] 25hz cosyvoiceåŸºç¡€æ¨¡å‹
    - [x] 25hz cosyvoiceå£°éŸ³è½¬æ¢æ¨¡å‹

- [x] 2024/08
    - [x] é‡å¤æ„ŸçŸ¥é‡‡æ ·(RAS)æ¨ç†ç”¨äºllmç¨³å®šæ€§
    - [x] æµå¼æ¨ç†æ¨¡å¼æ”¯æŒï¼ŒåŒ…æ‹¬kvç¼“å­˜å’Œsdpaç”¨äºrtfä¼˜åŒ–

- [x] 2024/07
    - [x] Flow matchingè®­ç»ƒæ”¯æŒ
    - [x] å½“ttsfrdä¸å¯ç”¨æ—¶æ”¯æŒWeTextProcessing
    - [x] FastapiæœåŠ¡å™¨å’Œå®¢æˆ·ç«¯

## å®‰è£…

### å…‹éš†å’Œå®‰è£…

- å…‹éš†ä»“åº“
    ``` sh
    git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git
    # å¦‚æœç”±äºç½‘ç»œå¤±è´¥æ— æ³•å…‹éš†å­æ¨¡å—ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ç›´åˆ°æˆåŠŸ
    cd CosyVoice
    git submodule update --init --recursive
    ```

- å®‰è£…Condaï¼šè¯·å‚è§ https://docs.conda.io/en/latest/miniconda.html
- åˆ›å»ºCondaç¯å¢ƒï¼š

    ``` sh
    conda create -n cosyvoice -y python=3.10
    conda activate cosyvoice
    # WeTextProcessingéœ€è¦pyniniï¼Œä½¿ç”¨condaå®‰è£…ï¼Œå› ä¸ºå®ƒå¯ä»¥åœ¨æ‰€æœ‰å¹³å°ä¸Šæ‰§è¡Œã€‚
    conda install -y -c conda-forge pynini==2.1.5
    pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com
    
    # å¦‚æœé‡åˆ°soxå…¼å®¹æ€§é—®é¢˜
    # ubuntu
    sudo apt-get install sox libsox-dev
    # centos
    sudo yum install sox sox-devel
    ```

### æ¨¡å‹ä¸‹è½½

æˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨ä¸‹è½½æˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ `CosyVoice2-0.5B` `CosyVoice-300M` `CosyVoice-300M-SFT` `CosyVoice-300M-Instruct` å’Œ `CosyVoice-ttsfrd` èµ„æºã€‚

``` python
# SDKæ¨¡å‹ä¸‹è½½
from modelscope import snapshot_download
snapshot_download('iic/CosyVoice2-0.5B', local_dir='pretrained_models/CosyVoice2-0.5B')
snapshot_download('iic/CosyVoice-300M', local_dir='pretrained_models/CosyVoice-300M')
snapshot_download('iic/CosyVoice-300M-SFT', local_dir='pretrained_models/CosyVoice-300M-SFT')
snapshot_download('iic/CosyVoice-300M-Instruct', local_dir='pretrained_models/CosyVoice-300M-Instruct')
snapshot_download('iic/CosyVoice-ttsfrd', local_dir='pretrained_models/CosyVoice-ttsfrd')
```

``` sh
# gitæ¨¡å‹ä¸‹è½½ï¼Œè¯·ç¡®ä¿å·²å®‰è£…git lfs
mkdir -p pretrained_models
git clone https://www.modelscope.cn/iic/CosyVoice2-0.5B.git pretrained_models/CosyVoice2-0.5B
git clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M
git clone https://www.modelscope.cn/iic/CosyVoice-300M-SFT.git pretrained_models/CosyVoice-300M-SFT
git clone https://www.modelscope.cn/iic/CosyVoice-300M-Instruct.git pretrained_models/CosyVoice-300M-Instruct
git clone https://www.modelscope.cn/iic/CosyVoice-ttsfrd.git pretrained_models/CosyVoice-ttsfrd
```

å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥è§£å‹ `ttsfrd` èµ„æºå¹¶å®‰è£… `ttsfrd` åŒ…ä»¥è·å¾—æ›´å¥½çš„æ–‡æœ¬æ ‡å‡†åŒ–æ€§èƒ½ã€‚

è¯·æ³¨æ„ï¼Œæ­¤æ­¥éª¤ä¸æ˜¯å¿…éœ€çš„ã€‚å¦‚æœæ‚¨ä¸å®‰è£… `ttsfrd` åŒ…ï¼Œæˆ‘ä»¬å°†é»˜è®¤ä½¿ç”¨WeTextProcessingã€‚

``` sh
cd pretrained_models/CosyVoice-ttsfrd/
unzip resource.zip -d .
pip install ttsfrd_dependency-0.1-py3-none-any.whl
pip install ttsfrd-0.4.2-cp310-cp310-linux_x86_64.whl
```

### åŸºæœ¬ç”¨æ³•

æˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½¿ç”¨ `CosyVoice2-0.5B` ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚
æŒ‰ç…§ä¸‹é¢çš„ä»£ç äº†è§£æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†ç”¨æ³•ã€‚

``` python
import sys
sys.path.append('third_party/Matcha-TTS')
from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2
from cosyvoice.utils.file_utils import load_wav
import torchaudio
```

#### CosyVoice2 ç”¨æ³•
```python
cosyvoice = CosyVoice2('pretrained_models/CosyVoice2-0.5B', load_jit=False, load_trt=False, load_vllm=False, fp16=False)

# æ³¨æ„ï¼šå¦‚æœä½ æƒ³é‡ç° https://funaudiollm.github.io/cosyvoice2 ä¸Šçš„ç»“æœï¼Œè¯·åœ¨æ¨ç†æ—¶æ·»åŠ  text_frontend=False
# é›¶æ ·æœ¬ç”¨æ³•
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_zero_shot('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# ä¿å­˜é›¶æ ·æœ¬è¯´è¯äººä»¥ä¾›å°†æ¥ä½¿ç”¨
assert cosyvoice.add_zero_shot_spk('å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, 'my_zero_shot_spk') is True
for i, j in enumerate(cosyvoice.inference_zero_shot('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', '', '', zero_shot_spk_id='my_zero_shot_spk', stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
cosyvoice.save_spkinfo()

# ç»†ç²’åº¦æ§åˆ¶ï¼Œæ”¯æŒçš„æ§åˆ¶è¯·æŸ¥çœ‹ cosyvoice/tokenizer/tokenizer.py#L248
for i, j in enumerate(cosyvoice.inference_cross_lingual('åœ¨ä»–è®²è¿°é‚£ä¸ªè’è¯æ•…äº‹çš„è¿‡ç¨‹ä¸­ï¼Œä»–çªç„¶[laughter]åœä¸‹æ¥ï¼Œå› ä¸ºä»–è‡ªå·±ä¹Ÿè¢«é€—ç¬‘äº†[laughter]ã€‚', prompt_speech_16k, stream=False)):
    torchaudio.save('fine_grained_control_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# æŒ‡ä»¤ç”¨æ³•
for i, j in enumerate(cosyvoice.inference_instruct2('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'ç”¨å››å·è¯è¯´è¿™å¥è¯', prompt_speech_16k, stream=False)):
    torchaudio.save('instruct_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# åŒæµç”¨æ³•ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ç”Ÿæˆå™¨ä½œä¸ºè¾“å…¥ï¼Œè¿™åœ¨ä½¿ç”¨æ–‡æœ¬llmæ¨¡å‹ä½œä¸ºè¾“å…¥æ—¶å¾ˆæœ‰ç”¨
# æ³¨æ„ï¼šæ‚¨ä»ç„¶åº”è¯¥æœ‰ä¸€äº›åŸºæœ¬çš„å¥å­åˆ†å‰²é€»è¾‘ï¼Œå› ä¸ºllmä¸èƒ½å¤„ç†ä»»æ„å¥å­é•¿åº¦
def text_generator():
    yield 'æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œ'
    yield 'é‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦'
    yield 'è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œ'
    yield 'ç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚'
for i, j in enumerate(cosyvoice.inference_zero_shot(text_generator(), 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
```

#### CosyVoice2 vllm ç”¨æ³•
å¦‚æœæ‚¨æƒ³ä½¿ç”¨vllmè¿›è¡Œæ¨ç†ï¼Œè¯·å®‰è£… `vllm==v0.9.0`ã€‚è¾ƒæ—§çš„vllmç‰ˆæœ¬ä¸æ”¯æŒCosyVoice2æ¨ç†ã€‚

è¯·æ³¨æ„ï¼Œ`vllm==v0.9.0` æœ‰å¾ˆå¤šç‰¹å®šè¦æ±‚ï¼Œä¾‹å¦‚ `torch==2.7.0`ã€‚æ‚¨å¯ä»¥åˆ›å»ºä¸€ä¸ªæ–°ç¯å¢ƒï¼Œä»¥é˜²æ‚¨çš„ç¡¬ä»¶ä¸æ”¯æŒvllmä¸”æ—§ç¯å¢ƒæŸåã€‚

``` sh
conda create -n cosyvoice_vllm --clone cosyvoice
conda activate cosyvoice_vllm
pip install vllm==v0.9.0 -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com
python vllm_example.py
```

#### CosyVoice ç”¨æ³•
```python
cosyvoice = CosyVoice('pretrained_models/CosyVoice-300M-SFT', load_jit=False, load_trt=False, fp16=False)
# sftç”¨æ³•
print(cosyvoice.list_available_spks())
# å°†stream=Trueæ”¹ä¸ºå—æµæ¨ç†
for i, j in enumerate(cosyvoice.inference_sft('ä½ å¥½ï¼Œæˆ‘æ˜¯é€šä¹‰ç”Ÿæˆå¼è¯­éŸ³å¤§æ¨¡å‹ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ', 'ä¸­æ–‡å¥³', stream=False)):
    torchaudio.save('sft_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

cosyvoice = CosyVoice('pretrained_models/CosyVoice-300M')
# é›¶æ ·æœ¬ç”¨æ³•ï¼Œ<|zh|><|en|><|jp|><|yue|><|ko|> åˆ†åˆ«è¡¨ç¤ºä¸­æ–‡/è‹±è¯­/æ—¥è¯­/ç²¤è¯­/éŸ©è¯­
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_zero_shot('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
# è·¨è¯­è¨€ç”¨æ³•
prompt_speech_16k = load_wav('./asset/cross_lingual_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_cross_lingual('<|en|>And then later on, fully acquiring that company. So keeping management in line, interest in line with the asset that\'s coming into the family is a reason why sometimes we don\'t buy the whole thing.', prompt_speech_16k, stream=False)):
    torchaudio.save('cross_lingual_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
# è¯­éŸ³è½¬æ¢ç”¨æ³•
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)
source_speech_16k = load_wav('./asset/cross_lingual_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_vc(source_speech_16k, prompt_speech_16k, stream=False)):
    torchaudio.save('vc_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

cosyvoice = CosyVoice('pretrained_models/CosyVoice-300M-Instruct')
# æŒ‡ä»¤ç”¨æ³•ï¼Œæ”¯æŒ <laughter></laughter><strong></strong>[laughter][breath]
for i, j in enumerate(cosyvoice.inference_instruct('åœ¨é¢å¯¹æŒ‘æˆ˜æ—¶ï¼Œä»–å±•ç°äº†éå‡¡çš„<strong>å‹‡æ°”</strong>ä¸<strong>æ™ºæ…§</strong>ã€‚', 'ä¸­æ–‡ç”·', 'Theo \'Crimson\', is a fiery, passionate rebel leader. Fights with fervor for justice, but struggles with impulsiveness.', stream=False)):
    torchaudio.save('instruct_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
```

#### å¯åŠ¨ç½‘é¡µæ¼”ç¤º

æ‚¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„ç½‘é¡µæ¼”ç¤ºé¡µé¢å¿«é€Ÿä¸Šæ‰‹CosyVoiceã€‚

æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§æ¼”ç¤ºç½‘ç«™ã€‚

``` python
# å°†iic/CosyVoice-300M-SFTæ”¹ä¸ºsftæ¨ç†ï¼Œæˆ–å°†iic/CosyVoice-300M-Instructæ”¹ä¸ºæŒ‡ä»¤æ¨ç†
python3 webui.py --port 50000 --model_dir pretrained_models/CosyVoice-300M
```

#### é«˜çº§ç”¨æ³•

å¯¹äºé«˜çº§ç”¨æˆ·ï¼Œæˆ‘ä»¬åœ¨ `examples/libritts/cosyvoice/run.sh` ä¸­æä¾›äº†è®­ç»ƒå’Œæ¨ç†è„šæœ¬ã€‚

#### æ„å»ºç”¨äºéƒ¨ç½²

å¯é€‰åœ°ï¼Œå¦‚æœæ‚¨æƒ³è¦æœåŠ¡éƒ¨ç½²ï¼Œ
æ‚¨å¯ä»¥è¿è¡Œä»¥ä¸‹æ­¥éª¤ã€‚

``` sh
cd runtime/python
docker build -t cosyvoice:v1.0 .
# å¦‚æœè¦ä½¿ç”¨æŒ‡ä»¤æ¨ç†ï¼Œè¯·å°†iic/CosyVoice-300Mæ›´æ”¹ä¸ºiic/CosyVoice-300M-Instruct
# grpcç”¨æ³•
docker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v1.0 /bin/bash -c "cd /opt/CosyVoice/CosyVoice/runtime/python/grpc && python3 server.py --port 50000 --max_conc 4 --model_dir iic/CosyVoice-300M && sleep infinity"
cd grpc && python3 client.py --port 50000 --mode <sft|zero_shot|cross_lingual|instruct>
# fastapiç”¨æ³•
docker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v1.0 /bin/bash -c "cd /opt/CosyVoice/CosyVoice/runtime/python/fastapi && python3 server.py --port 50000 --model_dir iic/CosyVoice-300M && sleep infinity"
cd fastapi && python3 client.py --port 50000 --mode <sft|zero_shot|cross_lingual|instruct>
```

## è®¨è®ºä¸äº¤æµ

æ‚¨å¯ä»¥ç›´æ¥åœ¨ [Github Issues](https://github.com/FunAudioLLM/CosyVoice/issues) ä¸Šè®¨è®ºã€‚

æ‚¨ä¹Ÿå¯ä»¥æ‰«æäºŒç»´ç åŠ å…¥æˆ‘ä»¬çš„å®˜æ–¹é’‰é’‰èŠå¤©ç¾¤ã€‚

<img src="./asset/dingding.png" width="250px">

## è‡´è°¢

1. æˆ‘ä»¬ä» [FunASR](https://github.com/modelscope/FunASR) å€Ÿç”¨äº†å¤§é‡ä»£ç ã€‚
2. æˆ‘ä»¬ä» [FunCodec](https://github.com/modelscope/FunCodec) å€Ÿç”¨äº†å¤§é‡ä»£ç ã€‚
3. æˆ‘ä»¬ä» [Matcha-TTS](https://github.com/shivammehta25/Matcha-TTS) å€Ÿç”¨äº†å¤§é‡ä»£ç ã€‚
4. æˆ‘ä»¬ä» [AcademiCodec](https://github.com/yangdongchao/AcademiCodec) å€Ÿç”¨äº†å¤§é‡ä»£ç ã€‚
5. æˆ‘ä»¬ä» [WeNet](https://github.com/wenet-e2e/wenet) å€Ÿç”¨äº†å¤§é‡ä»£ç ã€‚

## å…è´£å£°æ˜
ä¸Šè¿°å†…å®¹ä»…ä¾›å­¦æœ¯ç›®çš„ï¼Œæ—¨åœ¨å±•ç¤ºæŠ€æœ¯èƒ½åŠ›ã€‚ä¸€äº›ç¤ºä¾‹æ¥æºäºäº’è”ç½‘ã€‚å¦‚æœ‰ä»»ä½•å†…å®¹ä¾µçŠ¯æ‚¨çš„æƒåˆ©ï¼Œè¯·è”ç³»æˆ‘ä»¬è¦æ±‚åˆ é™¤ã€‚ 